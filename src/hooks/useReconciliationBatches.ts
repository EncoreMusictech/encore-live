
import { useState, useEffect } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useAuth } from './useAuth';
import { toast } from '@/hooks/use-toast';
import { getQuarterFromDate } from '@/lib/utils';

export interface ReconciliationBatch {
  id: string;
  user_id: string;
  batch_id: string | null;
  source: 'DSP' | 'PRO' | 'YouTube' | 'BMI' | 'ASCAP' | 'SESAC' | 'SOCAN' | 'Spotify' | 'Apple Music' | 'Amazon Music' | 'Tidal' | 'Pandora' | 'SiriusXM' | 'Test Source' | 'Shondaland' | 'NBC' | 'Other';
  statement_period_start?: string;
  statement_period_end?: string;
  date_received: string;
  total_gross_amount: number;
  allocated_amount?: number; // Sum of allocated royalties
  reconciliation_status?: 'Complete' | 'Incomplete'; // Calculated field
  linked_statement_id?: string;
  statement_file_url?: string;
  status: 'Pending' | 'Imported' | 'Processed';
  notes?: string;
  processed_at?: string;
  processed_by_user_id?: string;
  unprocessed_at?: string;
  unprocessed_by_user_id?: string;
  processing_count?: number;
  created_at: string;
  updated_at: string;
}

export function useReconciliationBatches() {
  const [batches, setBatches] = useState<ReconciliationBatch[]>([]);
  const [loading, setLoading] = useState(true);
  const { user } = useAuth();

  const fetchBatches = async () => {
    if (!user) return;
    
    try {
      // First get the batches
      const { data: batchData, error: batchError } = await supabase
        .from('reconciliation_batches')
        .select('*')
        .order('created_at', { ascending: false });

      if (batchError) throw batchError;

      // Then get the allocated amounts for each batch
      const batchesWithAllocations = await Promise.all(
        (batchData || []).map(async (batch) => {
          let allocated_amount = 0;

          // Get the sum of gross_royalty_amount for all allocations linked to this batch via batch_id
          const { data: allocations, error: allocError } = await supabase
            .from('royalty_allocations')
            .select('gross_royalty_amount')
            .eq('batch_id', batch.id);

          if (allocError) {
            console.warn(`Error fetching allocations for batch ${batch.id}:`, allocError);
          } else {
            allocated_amount += allocations?.reduce((sum, allocation) => 
              sum + (allocation.gross_royalty_amount || 0), 0) || 0;
          }

          // If batch has a linked statement, also include royalties from that statement
          if (batch.linked_statement_id) {
            // First get the staging record to find its statement_id
            const { data: stagingRecord } = await supabase
              .from('royalties_import_staging')
              .select('statement_id')
              .eq('id', batch.linked_statement_id)
              .single();

            if (stagingRecord?.statement_id) {
              // Search for royalties using the staging record's statement_id
              const { data: statementRoyalties } = await supabase
                .from('royalty_allocations')
                .select('gross_royalty_amount')
                .eq('user_id', user.id)
                .eq('statement_id', stagingRecord.statement_id);

              if (statementRoyalties && statementRoyalties.length > 0) {
                allocated_amount += statementRoyalties.reduce((sum, allocation) => 
                  sum + (allocation.gross_royalty_amount || 0), 0);
              }
            }
          }

          // Calculate reconciliation status
          const reconciliation_status: 'Complete' | 'Incomplete' = Math.abs(allocated_amount - batch.total_gross_amount) < 0.01 
            ? 'Complete' 
            : 'Incomplete';

          return { ...batch, allocated_amount, reconciliation_status };
        })
      );

      setBatches(batchesWithAllocations);
    } catch (error: any) {
      console.error('Error fetching batches:', error);
      toast({
        title: "Error",
        description: "Failed to fetch reconciliation batches",
        variant: "destructive",
      });
    } finally {
      setLoading(false);
    }
  };

  const createBatch = async (batchData: Omit<ReconciliationBatch, 'id' | 'user_id' | 'batch_id' | 'created_at' | 'updated_at'>) => {
    if (!user) return null;

    try {
      const { data, error } = await supabase
        .from('reconciliation_batches')
        .insert({
          ...batchData,
          user_id: user.id,
          batch_id: null, // Will be auto-generated by trigger
        })
        .select()
        .single();

      if (error) throw error;

      toast({
        title: "Success",
        description: `Reconciliation batch ${data.batch_id} created successfully`,
      });

      await fetchBatches();
      return data;
    } catch (error: any) {
      console.error('Error creating batch:', error);
      toast({
        title: "Error",
        description: "Failed to create reconciliation batch",
        variant: "destructive",
      });
      return null;
    }
  };

  const updateBatch = async (id: string, batchData: Partial<ReconciliationBatch>) => {
    try {
      const { data, error } = await supabase
        .from('reconciliation_batches')
        .update(batchData)
        .eq('id', id)
        .select()
        .single();

      if (error) throw error;

      // If the batch status is being updated to 'Processed', also update the linked import staging record
      if (batchData.status === 'Processed' && data.linked_statement_id) {
        console.log('Updating linked import staging record status to processed');
        
        const { error: stagingUpdateError } = await supabase
          .from('royalties_import_staging')
          .update({ 
            processing_status: 'processed'
          })
          .eq('id', data.linked_statement_id);

        if (stagingUpdateError) {
          console.error('Error updating staging record status:', stagingUpdateError);
          // Don't fail the whole operation, just log the error
          toast({
            title: "Warning",
            description: "Batch updated but failed to sync import staging status",
            variant: "destructive",
          });
        } else {
          console.log('Successfully updated linked import staging record status');
        }
      }

      toast({
        title: "Success",
        description: "Reconciliation batch updated successfully",
      });

      await fetchBatches();
      return data;
    } catch (error: any) {
      console.error('Error updating batch:', error);
      toast({
        title: "Error",
        description: "Failed to update reconciliation batch",
        variant: "destructive",
      });
      return null;
    }
  };

  const deleteBatch = async (id: string) => {
    try {
      const { error } = await supabase
        .from('reconciliation_batches')
        .delete()
        .eq('id', id);

      if (error) throw error;

      toast({
        title: "Success",
        description: "Reconciliation batch deleted successfully",
      });

      await fetchBatches();
    } catch (error: any) {
      console.error('Error deleting batch:', error);
      toast({
        title: "Error",
        description: "Failed to delete reconciliation batch",
        variant: "destructive",
      });
    }
  };

  const linkBatchToAllocations = async (batchId: string, allocationIds: string[]) => {
    try {
      // First, get the batch's date_received to calculate the quarter
      const { data: batch, error: batchError } = await supabase
        .from('reconciliation_batches')
        .select('date_received')
        .eq('id', batchId)
        .single();

      if (batchError) throw batchError;
      
      // Calculate quarter from the batch's date_received
      const quarter = getQuarterFromDate(batch.date_received);

      // Update all specified allocations to link them to this batch and set the quarter
      const updatePromises = allocationIds.map(allocationId =>
        supabase
          .from('royalty_allocations')
          .update({ 
            batch_id: batchId,
            quarter: quarter
          })
          .eq('id', allocationId)
      );

      const results = await Promise.all(updatePromises);
      
      // Check for any errors
      const errors = results.filter(result => result.error);
      if (errors.length > 0) {
        throw new Error(`Failed to link ${errors.length} allocations`);
      }

      toast({
        title: "Success",
        description: `Successfully linked ${allocationIds.length} allocation${allocationIds.length !== 1 ? 's' : ''} to batch with quarter ${quarter}`,
      });

      await fetchBatches();
      return true;
    } catch (error: any) {
      console.error('Error linking batch to allocations:', error);
      toast({
        title: "Error",
        description: "Failed to link allocations to batch",
        variant: "destructive",
      });
      return false;
    }
  };

  const unlinkStatement = async (id: string) => {
    try {
      const { data, error } = await supabase
        .from('reconciliation_batches')
        .update({ linked_statement_id: null })
        .eq('id', id)
        .select()
        .single();

      if (error) throw error;

      // Update the local state
      setBatches(prevBatches => 
        prevBatches.map(batch => 
          batch.id === id 
            ? { ...batch, linked_statement_id: null }
            : batch
        )
      );

      toast({
        title: "Success",
        description: "Statement unlinked from batch successfully",
      });

      return data;
    } catch (error) {
      console.error('Error unlinking statement:', error);
      toast({
        title: "Error",
        description: "Failed to unlink statement from batch",
        variant: "destructive",
      });
      return null;
    }
  };

  const processBatch = async (id: string, quarter?: number, year?: number) => {
    if (!user) return false;

    // Default to current quarter and year if not specified
    const currentDate = new Date();
    const currentQuarter = Math.ceil((currentDate.getMonth() + 1) / 3);
    const currentYear = currentDate.getFullYear();
    
    const selectedQuarter = quarter || currentQuarter;
    const selectedYear = year || currentYear;

    try {
      const batch = batches.find(b => b.id === id);
      if (!batch) {
        toast({
          title: "Error",
          description: "Batch not found",
          variant: "destructive",
        });
        return false;
      }

      // Get all royalty allocations linked to this batch
      const { data: allocations, error: allocError } = await supabase
        .from('royalty_allocations')
        .select('*')
        .eq('batch_id', id);

      if (allocError) throw allocError;

      // Also get royalties from linked statement if any
      let linkedStatementRoyalties: any[] = [];
      
      if (batch?.linked_statement_id) {
        const { data: stagingRecord } = await supabase
          .from('royalties_import_staging')
          .select('statement_id')
          .eq('id', batch.linked_statement_id)
          .single();

        if (stagingRecord?.statement_id) {
          const { data: statementRoyalties } = await supabase
            .from('royalty_allocations')
            .select('*')
            .eq('user_id', user.id)
            .eq('statement_id', stagingRecord.statement_id);

          linkedStatementRoyalties = statementRoyalties || [];
        }
      }

      const allRoyalties = [...(allocations || []), ...linkedStatementRoyalties];

      if (allRoyalties.length === 0) {
        toast({
          title: "Error",
          description: "No royalties found to process",
          variant: "destructive",
        });
        return false;
      }

      // Group royalties by writer (supports multi-writer strings)
      const writerGroups = new Map<string, any[]>();
      const unmatched: any[] = [];

      // Get all writers for matching
      const { data: writers, error: writersError } = await supabase
        .from('writers')
        .select('id, writer_id, writer_name')
        .eq('user_id', user.id);
      if (writersError) throw writersError;

      const normalize = (s: string) => s.toLowerCase().replace(/[^a-z0-9\s]/g, "").replace(/\s+/g, " ").trim();

      // Map of normalized writer name -> writer record
      const writerNameMap = new Map(
        (writers || []).map((w) => [normalize(w.writer_name), w])
      );

      const splitWriters = (s: string): string[] =>
        s
          .split(/;|,|\&|\/|\band\b/gi)
          .map((t) => t.trim())
          .filter(Boolean);

      for (const royalty of allRoyalties) {
        const gross = royalty.gross_royalty_amount || 0;
        const names = royalty.work_writers ? splitWriters(royalty.work_writers) : [];
        const matches = names
          .map((n: string) => writerNameMap.get(normalize(n)))
          .filter((w): w is { id: string; writer_name: string; writer_id: string } => Boolean(w));

        if (matches.length === 1) {
          const w = matches[0]!;
          if (!writerGroups.has(w.id)) writerGroups.set(w.id, []);
          writerGroups.get(w.id)!.push({ ...royalty, writer_info: w, allocated_amount: gross });
        } else if (matches.length > 1) {
          const perWriter = gross / matches.length;
          for (const w of matches) {
            if (!writerGroups.has(w.id)) writerGroups.set(w.id, []);
            writerGroups.get(w.id)!.push({ ...royalty, writer_info: w, allocated_amount: perWriter });
          }
        } else {
          unmatched.push(royalty);
        }
      }

      // Create payouts for each writer group
      const payoutResults: any[] = [];

      for (const [writerId, writerRoyalties] of writerGroups) {
        const writer = writerRoyalties[0].writer_info;
        const totalAmount = writerRoyalties.reduce((sum, r) => sum + (r.allocated_amount ?? r.gross_royalty_amount ?? 0), 0);

        if (totalAmount <= 0) continue;

        try {
          // First, ensure a contact exists for this writer
          let contact;
          const { data: existingContact } = await supabase
            .from('contacts')
            .select('id')
            .eq('user_id', user.id)
            .eq('name', writer.writer_name)
            .eq('contact_type', 'writer')
            .maybeSingle();

          if (existingContact) {
            contact = existingContact;
          } else {
            // Create a contact for this writer
            const { data: newContact, error: contactError } = await supabase
              .from('contacts')
              .insert({
                user_id: user.id,
                name: writer.writer_name,
                contact_type: 'writer'
              })
              .select('id')
              .single();

            if (contactError) {
              console.error(`Error creating contact for writer ${writer.writer_name}:`, contactError);
              continue;
            }
            contact = newContact;
          }

          // Create writer-specific payout using contact_id
          const { data: payout, error: payoutError } = await supabase
            .from('payouts')
            .insert({
              user_id: user.id,
              client_id: contact.id, // Use contact ID instead of writer ID
              period: `Q${selectedQuarter} ${selectedYear}`,
              period_start: `${selectedYear}-${(selectedQuarter - 1) * 3 + 1}-01`,
              period_end: `${selectedYear}-${selectedQuarter * 3}-${selectedQuarter === 4 ? 31 : 30}`,
              gross_royalties: totalAmount,
              total_expenses: 0,
              net_payable: totalAmount,
              amount_due: totalAmount,
              status: 'pending',
              notes: `Auto-generated for writer ${writer.writer_name} from batch ${batch?.batch_id || id} - Q${selectedQuarter} ${selectedYear}`,
            })
            .select()
            .single();

          if (payoutError) {
            console.error(`Error creating payout for writer ${writer.writer_name}:`, payoutError);
            continue;
          }

        // Link royalties to the payout (use allocated_amount when provided)
        const payoutRoyalties = writerRoyalties.map(royalty => ({
          payout_id: payout.id,
          royalty_id: royalty.id,
          allocated_amount: royalty.allocated_amount ?? (royalty.gross_royalty_amount || 0),
        }));

        const { error: linkError } = await supabase
          .from('payout_royalties')
          .insert(payoutRoyalties);

        if (linkError) {
          console.error(`Error linking royalties for writer ${writer.writer_name}:`, linkError);
          continue;
        }

        // Update quarterly balance reports for writer's payees
        const { data: payees } = await supabase
          .from('payees')
          .select('id')
          .eq('user_id', user.id)
          .eq('writer_id', writerId);

        if (payees && payees.length > 0) {
          for (const payee of payees) {
            // Check if quarterly report exists
            const { data: existingReport } = await supabase
              .from('quarterly_balance_reports')
              .select('id, opening_balance')
              .eq('user_id', user.id)
              .eq('payee_id', payee.id)
              .eq('quarter', selectedQuarter)
              .eq('year', selectedYear)
              .single();

            if (existingReport) {
              // Update existing report
              await supabase
                .from('quarterly_balance_reports')
                .update({
                  royalties_amount: totalAmount,
                  closing_balance: (existingReport.opening_balance || 0) + totalAmount,
                  updated_at: new Date().toISOString(),
                })
                .eq('id', existingReport.id);
            } else {
              // Create new quarterly report
              await supabase
                .from('quarterly_balance_reports')
                .insert({
                  user_id: user.id,
                  payee_id: payee.id,
                  quarter: selectedQuarter,
                  year: selectedYear,
                  opening_balance: 0,
                  royalties_amount: totalAmount,
                  expenses_amount: 0,
                  payments_amount: 0,
                  closing_balance: totalAmount,
                });
            }
          }
        }

          payoutResults.push({
            writer_name: writer.writer_name,
            writer_id: writer.writer_id,
            payout_id: payout.id,
            amount: totalAmount,
            royalty_count: writerRoyalties.length,
            payee_count: payees?.length || 0,
          });
        } catch (error) {
          console.error(`Error processing writer ${writer.writer_name}:`, error);
          toast({
            title: "Warning",
            description: `Failed to create payout for writer ${writer.writer_name}`,
            variant: "destructive",
          });
        }
      }

      // Handle unmatched royalties (create a general payout if needed)
      if (unmatched.length > 0) {
        const unmatchedTotal = unmatched.reduce((sum, r) => sum + (r.gross_royalty_amount || 0), 0);
        
        if (unmatchedTotal > 0) {
          // Create or find an "Unmatched" contact for unmatched royalties
          let unmatchedContact;
          const { data: existingUnmatchedContact } = await supabase
            .from('contacts')
            .select('id')
            .eq('user_id', user.id)
            .eq('name', 'Unmatched Royalties')
            .eq('contact_type', 'other')
            .maybeSingle();

          if (existingUnmatchedContact) {
            unmatchedContact = existingUnmatchedContact;
          } else {
            const { data: newUnmatchedContact, error: unmatchedContactError } = await supabase
              .from('contacts')
              .insert({
                user_id: user.id,
                name: 'Unmatched Royalties',
                contact_type: 'other'
              })
              .select('id')
              .single();

            if (unmatchedContactError) {
              console.error('Error creating unmatched contact:', unmatchedContactError);
              // Skip unmatched payout creation if contact creation fails
              unmatchedContact = null;
            } else {
              unmatchedContact = newUnmatchedContact;
            }
          }

          if (unmatchedContact) {
            const { data: unmatchedPayout, error: unmatchedError } = await supabase
              .from('payouts')
              .insert({
                user_id: user.id,
                client_id: unmatchedContact.id,
                period: `Q${selectedQuarter} ${selectedYear}`,
                period_start: `${selectedYear}-${(selectedQuarter - 1) * 3 + 1}-01`,
                period_end: `${selectedYear}-${selectedQuarter * 3}-${selectedQuarter === 4 ? 31 : 30}`,
                gross_royalties: unmatchedTotal,
                total_expenses: 0,
                net_payable: unmatchedTotal,
                amount_due: unmatchedTotal,
                status: 'pending',
                notes: `Unmatched royalties from batch ${batch?.batch_id || id} - Q${selectedQuarter} ${selectedYear}`,
              })
              .select()
              .single();

            if (!unmatchedError) {
              const unmatchedRoyalties = unmatched.map(royalty => ({
                payout_id: unmatchedPayout.id,
                royalty_id: royalty.id,
                allocated_amount: royalty.gross_royalty_amount || 0,
              }));

              await supabase
                .from('payout_royalties')
                .insert(unmatchedRoyalties);

              payoutResults.push({
                writer_name: 'Unmatched',
                writer_id: 'unmatched',
                payout_id: unmatchedPayout.id,
                amount: unmatchedTotal,
                royalty_count: unmatched.length,
                payee_count: 0,
              });
            }
          }
        }
      }

      // Update the batch to mark it as processed
      const { error: updateError } = await supabase
        .from('reconciliation_batches')
        .update({
          processed_at: new Date().toISOString(),
          processed_by_user_id: user.id,
          processing_count: (batch?.processing_count || 0) + 1,
        })
        .eq('id', id);

      if (updateError) throw updateError;

      toast({
        title: "Success",
        description: `Batch processed successfully. Created ${payoutResults.length} writer-specific payouts.`,
      });

      await fetchBatches();
      return true;
    } catch (error: any) {
      console.error('Error processing batch:', error);
      toast({
        title: "Error",
        description: "Failed to process batch to writer payouts",
        variant: "destructive",
      });
      return false;
    }
  };

  const unprocessBatch = async (id: string) => {
    if (!user) return false;

    try {
      // Find all payouts that were created from this batch
      const batch = batches.find(b => b.id === id);
      const { data: payouts, error: payoutError } = await supabase
        .from('payouts')
        .select('id')
        .eq('user_id', user.id)
        .like('notes', `%from batch ${batch?.batch_id || id}%`);

      if (payoutError) throw payoutError;

      if (payouts && payouts.length > 0) {
        // Delete payout royalty links
        const { error: deleteLinksError } = await supabase
          .from('payout_royalties')
          .delete()
          .in('payout_id', payouts.map(p => p.id));

        if (deleteLinksError) throw deleteLinksError;

        // Delete the payouts
        const { error: deletePayoutsError } = await supabase
          .from('payouts')
          .delete()
          .in('id', payouts.map(p => p.id));

        if (deletePayoutsError) throw deletePayoutsError;
      }

      // Update the batch to mark it as unprocessed
      const { error: updateError } = await supabase
        .from('reconciliation_batches')
        .update({
          unprocessed_at: new Date().toISOString(),
          unprocessed_by_user_id: user.id,
        })
        .eq('id', id);

      if (updateError) throw updateError;

      toast({
        title: "Success",
        description: "Batch unprocessed successfully. Associated payouts have been removed.",
      });

      await fetchBatches();
      return true;
    } catch (error: any) {
      console.error('Error unprocessing batch:', error);
      toast({
        title: "Error",
        description: "Failed to unprocess batch",
        variant: "destructive",
      });
      return false;
    }
  };

  useEffect(() => {
    fetchBatches();
  }, [user]);

  return {
    batches,
    loading,
    createBatch,
    updateBatch,
    deleteBatch,
    linkBatchToAllocations,
    unlinkStatement,
    processBatch,
    unprocessBatch,
    refreshBatches: fetchBatches,
  };
}
