
import { useState, useEffect } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useAuth } from './useAuth';
import { toast } from '@/hooks/use-toast';
import { getQuarterFromDate } from '@/lib/utils';

export interface ReconciliationBatch {
  id: string;
  user_id: string;
  batch_id: string | null;
  source: 'DSP' | 'PRO' | 'YouTube' | 'BMI' | 'ASCAP' | 'SESAC' | 'SOCAN' | 'Spotify' | 'Apple Music' | 'Amazon Music' | 'Tidal' | 'Pandora' | 'SiriusXM' | 'Test Source' | 'Shondaland' | 'NBC' | 'SoundExchange' | 'NFL Productions' | 'Other';
  statement_period_start?: string;
  statement_period_end?: string;
  date_received: string;
  total_gross_amount: number;
  allocated_amount?: number; // Sum of allocated royalties
  reconciliation_status?: 'Complete' | 'Incomplete'; // Calculated field
  linked_statement_id?: string;
  statement_file_url?: string;
  status: 'Pending' | 'Imported' | 'Processed';
  notes?: string;
  processed_at?: string;
  processed_by_user_id?: string;
  unprocessed_at?: string;
  unprocessed_by_user_id?: string;
  processing_count?: number;
  created_at: string;
  updated_at: string;
}

export function useReconciliationBatches() {
  const [batches, setBatches] = useState<ReconciliationBatch[]>([]);
  const [loading, setLoading] = useState(true);
  const { user } = useAuth();

  const fetchBatches = async () => {
    if (!user) return;
    
    try {
      // First get the batches
      const { data: batchData, error: batchError } = await supabase
        .from('reconciliation_batches')
        .select('*')
        .order('created_at', { ascending: false });

      if (batchError) throw batchError;

      // Then get the allocated amounts for each batch
      const batchesWithAllocations = await Promise.all(
        (batchData || []).map(async (batch) => {
          let allocated_amount = 0;

          // Get the sum of gross_royalty_amount for all allocations linked to this batch via batch_id
          const { data: allocations, error: allocError } = await supabase
            .from('royalty_allocations')
            .select('gross_royalty_amount')
            .eq('batch_id', batch.id);

          if (allocError) {
            console.warn(`Error fetching allocations for batch ${batch.id}:`, allocError);
          } else {
            allocated_amount += allocations?.reduce((sum, allocation) => 
              sum + (allocation.gross_royalty_amount || 0), 0) || 0;
          }

          // If batch has a linked statement, also include royalties from that statement
          if (batch.linked_statement_id) {
            // First get the staging record to find its statement_id
            const { data: stagingRecord } = await supabase
              .from('royalties_import_staging')
              .select('statement_id')
              .eq('id', batch.linked_statement_id)
              .single();

            if (stagingRecord?.statement_id) {
              // Search for royalties using the staging record's statement_id
              const { data: statementRoyalties } = await supabase
                .from('royalty_allocations')
                .select('gross_royalty_amount')
                .eq('user_id', user.id)
                .eq('statement_id', stagingRecord.statement_id);

              if (statementRoyalties && statementRoyalties.length > 0) {
                allocated_amount += statementRoyalties.reduce((sum, allocation) => 
                  sum + (allocation.gross_royalty_amount || 0), 0);
              }
            }
          }

          // Calculate reconciliation status
          const reconciliation_status: 'Complete' | 'Incomplete' = Math.abs(allocated_amount - batch.total_gross_amount) < 0.01 
            ? 'Complete' 
            : 'Incomplete';

          return { ...batch, allocated_amount, reconciliation_status };
        })
      );

      setBatches(batchesWithAllocations);
    } catch (error: any) {
      console.error('Error fetching batches:', error);
      toast({
        title: "Error",
        description: "Failed to fetch reconciliation batches",
        variant: "destructive",
      });
    } finally {
      setLoading(false);
    }
  };

  const createBatch = async (batchData: Omit<ReconciliationBatch, 'id' | 'user_id' | 'batch_id' | 'created_at' | 'updated_at'>) => {
    if (!user) return null;

    try {
      const { data, error } = await supabase
        .from('reconciliation_batches')
        .insert({
          ...batchData,
          user_id: user.id,
          batch_id: null, // Will be auto-generated by trigger
        })
        .select()
        .single();

      if (error) throw error;

      toast({
        title: "Success",
        description: `Reconciliation batch ${data.batch_id} created successfully`,
      });

      await fetchBatches();
      return data;
    } catch (error: any) {
      console.error('Error creating batch:', error);
      toast({
        title: "Error",
        description: "Failed to create reconciliation batch",
        variant: "destructive",
      });
      return null;
    }
  };

  const updateBatch = async (id: string, batchData: Partial<ReconciliationBatch>) => {
    try {
      const { data, error } = await supabase
        .from('reconciliation_batches')
        .update(batchData)
        .eq('id', id)
        .select()
        .single();

      if (error) throw error;

      // If the batch status is being updated to 'Processed', also update the linked import staging record
      if (batchData.status === 'Processed' && data.linked_statement_id) {
        console.log('Updating linked import staging record status to processed');
        
        const { error: stagingUpdateError } = await supabase
          .from('royalties_import_staging')
          .update({ 
            processing_status: 'processed'
          })
          .eq('id', data.linked_statement_id);

        if (stagingUpdateError) {
          console.error('Error updating staging record status:', stagingUpdateError);
          // Don't fail the whole operation, just log the error
          toast({
            title: "Warning",
            description: "Batch updated but failed to sync import staging status",
            variant: "destructive",
          });
        } else {
          console.log('Successfully updated linked import staging record status');
        }
      }

      toast({
        title: "Success",
        description: "Reconciliation batch updated successfully",
      });

      await fetchBatches();
      return data;
    } catch (error: any) {
      console.error('Error updating batch:', error);
      toast({
        title: "Error",
        description: "Failed to update reconciliation batch",
        variant: "destructive",
      });
      return null;
    }
  };

  const deleteBatch = async (id: string) => {
    try {
      const { error } = await supabase
        .from('reconciliation_batches')
        .delete()
        .eq('id', id);

      if (error) throw error;

      toast({
        title: "Success",
        description: "Reconciliation batch deleted successfully",
      });

      await fetchBatches();
    } catch (error: any) {
      console.error('Error deleting batch:', error);
      toast({
        title: "Error",
        description: "Failed to delete reconciliation batch",
        variant: "destructive",
      });
    }
  };

  const linkBatchToAllocations = async (batchId: string, allocationIds: string[]) => {
    try {
      // First, get the batch's date_received to calculate the quarter
      const { data: batch, error: batchError } = await supabase
        .from('reconciliation_batches')
        .select('date_received')
        .eq('id', batchId)
        .single();

      if (batchError) throw batchError;
      
      // Calculate quarter from the batch's date_received
      const quarter = getQuarterFromDate(batch.date_received);

      // Update all specified allocations to link them to this batch and set the quarter
      const updatePromises = allocationIds.map(allocationId =>
        supabase
          .from('royalty_allocations')
          .update({ 
            batch_id: batchId,
            quarter: quarter
          })
          .eq('id', allocationId)
      );

      const results = await Promise.all(updatePromises);
      
      // Check for any errors
      const errors = results.filter(result => result.error);
      if (errors.length > 0) {
        throw new Error(`Failed to link ${errors.length} allocations`);
      }

      toast({
        title: "Success",
        description: `Successfully linked ${allocationIds.length} allocation${allocationIds.length !== 1 ? 's' : ''} to batch with quarter ${quarter}`,
      });

      await fetchBatches();
      return true;
    } catch (error: any) {
      console.error('Error linking batch to allocations:', error);
      toast({
        title: "Error",
        description: "Failed to link allocations to batch",
        variant: "destructive",
      });
      return false;
    }
  };

  const unlinkStatement = async (id: string) => {
    try {
      const { data, error } = await supabase
        .from('reconciliation_batches')
        .update({ linked_statement_id: null })
        .eq('id', id)
        .select()
        .single();

      if (error) throw error;

      // Update the local state
      setBatches(prevBatches => 
        prevBatches.map(batch => 
          batch.id === id 
            ? { ...batch, linked_statement_id: null }
            : batch
        )
      );

      toast({
        title: "Success",
        description: "Statement unlinked from batch successfully",
      });

      return data;
    } catch (error) {
      console.error('Error unlinking statement:', error);
      toast({
        title: "Error",
        description: "Failed to unlink statement from batch",
        variant: "destructive",
      });
      return null;
    }
  };

  const processBatch = async (id: string, quarter?: number, year?: number) => {
    if (!user) return false;

    // Default to current quarter and year if not specified
    const currentDate = new Date();
    const currentQuarter = Math.ceil((currentDate.getMonth() + 1) / 3);
    const currentYear = currentDate.getFullYear();
    
    const selectedQuarter = quarter || currentQuarter;
    const selectedYear = year || currentYear;

    try {
      const batch = batches.find(b => b.id === id);
      if (!batch) {
        toast({
          title: "Error",
          description: "Batch not found",
          variant: "destructive",
        });
        return false;
      }

      // Get all royalty allocations linked to this batch
      const { data: allocations, error: allocError } = await supabase
        .from('royalty_allocations')
        .select('*')
        .eq('batch_id', id);

      if (allocError) throw allocError;

      // Also get royalties from linked statement if any
      let linkedStatementRoyalties: any[] = [];
      
      if (batch?.linked_statement_id) {
        const { data: stagingRecord } = await supabase
          .from('royalties_import_staging')
          .select('statement_id')
          .eq('id', batch.linked_statement_id)
          .single();

        if (stagingRecord?.statement_id) {
          const { data: statementRoyalties } = await supabase
            .from('royalty_allocations')
            .select('*')
            .eq('user_id', user.id)
            .eq('statement_id', stagingRecord.statement_id);

          linkedStatementRoyalties = statementRoyalties || [];
        }
      }

      const allRoyalties = [...(allocations || []), ...linkedStatementRoyalties];

      // Get all writers for matching
      const { data: writers, error: writersError } = await supabase
        .from('writers')
        .select('id, writer_id, writer_name')
        .eq('user_id', user.id);
      if (writersError) throw writersError;

      // Get all payees (with writer info) for matching
      const { data: payees, error: payeesError } = await supabase
        .from('payees')
        .select('*, writers(id, writer_id, writer_name)')
        .eq('user_id', user.id);
      if (payeesError) throw payeesError;

      const normalize = (s: string) => s.toLowerCase().replace(/[^a-z0-9\s]/g, "").replace(/\s+/g, " ").trim();

      const splitWriters = (s: string): string[] =>
        s
          .split(/;|,|\&|\/|\band\b/gi)
          .map((t) => t.trim())
          .filter(Boolean);

      // Extract all unique writer names from royalty data and ensure contacts exist
      const allWriterNames = new Set<string>();
      for (const royalty of allRoyalties) {
        if (royalty.work_writers) {
          const names = splitWriters(royalty.work_writers);
          names.forEach(name => {
            if (name && name.trim()) {
              allWriterNames.add(name.trim());
            }
          });
        }
      }

      // Get existing contacts for writers
      const { data: existingContacts } = await supabase
        .from('contacts')
        .select('id, name')
        .eq('user_id', user.id)
        .eq('contact_type', 'writer');

      const contactNameMap = new Map(
        (existingContacts || []).map((c) => [normalize(c.name), c])
      );

      // Create contacts for any new writer names
      const newContactsCreated: string[] = [];
      for (const writerName of allWriterNames) {
        const normalizedName = normalize(writerName);
        if (!contactNameMap.has(normalizedName)) {
          try {
            const { data: newContact, error: contactError } = await supabase
              .from('contacts')
              .insert({
                user_id: user.id,
                name: writerName,
                contact_type: 'writer',
              })
              .select('id, name')
              .single();

            if (contactError) {
              console.error(`Error creating contact for ${writerName}:`, contactError);
            } else {
              contactNameMap.set(normalizedName, newContact);
              newContactsCreated.push(writerName);
              console.log(`Created contact for writer: ${writerName}`);
            }
          } catch (error) {
            console.error(`Error creating contact for ${writerName}:`, error);
          }
        }
      }

      if (newContactsCreated.length > 0) {
        toast({
          title: "Contacts Created",
          description: `Automatically created ${newContactsCreated.length} new contacts for writers: ${newContactsCreated.slice(0, 3).join(', ')}${newContactsCreated.length > 3 ? '...' : ''}`,
        });
      }

      // Map of normalized writer name -> writer record (keep for backward compatibility)
      const writerNameMap = new Map(
        (writers || []).map((w) => [normalize(w.writer_name), w])
      );

      // Preload control information by copyright and agreements
      const uniqueCopyrightIds = Array.from(
        new Set((allRoyalties || []).map((r: any) => r.copyright_id).filter(Boolean))
      );

      let copyrightWriterRows: any[] = [];
      let scheduleWorkRows: any[] = [];
      let interestedPartyRows: any[] = [];

      if (uniqueCopyrightIds.length > 0) {
        const [{ data: cw }, { data: sw }] = await Promise.all([
          supabase
            .from('copyright_writers')
            .select('copyright_id, writer_name, controlled_status')
            .in('copyright_id', uniqueCopyrightIds),
          supabase
            .from('contract_schedule_works')
            .select('contract_id, copyright_id, inherits_controlled_status')
            .in('copyright_id', uniqueCopyrightIds),
        ]);

        copyrightWriterRows = cw || [];
        scheduleWorkRows = sw || [];

        const contractIds = Array.from(new Set(scheduleWorkRows.map((s: any) => s.contract_id).filter(Boolean)));
        if (contractIds.length > 0) {
          const { data: ip } = await supabase
            .from('contract_interested_parties')
            .select('contract_id, name, party_type, controlled_status')
            .in('contract_id', contractIds)
            .eq('party_type', 'writer');
          interestedPartyRows = ip || [];
        }
      }

      // Build quick-lookup maps of controlled names
      const controlledByCopyright = new Map<string, Set<string>>();
      for (const row of copyrightWriterRows) {
        if ((row.controlled_status || '') === 'C') {
          const key = row.copyright_id as string;
          if (!controlledByCopyright.has(key)) controlledByCopyright.set(key, new Set());
          controlledByCopyright.get(key)!.add(normalize(row.writer_name));
        }
      }

      const controlledByAgreement = new Map<string, Set<string>>();
      for (const sw of scheduleWorkRows) {
        if (!sw.inherits_controlled_status) continue;
        const parties = interestedPartyRows.filter((p: any) => p.contract_id === sw.contract_id && (p.controlled_status || '') === 'C');
        if (parties.length === 0) continue;
        const key = sw.copyright_id as string;
        if (!controlledByAgreement.has(key)) controlledByAgreement.set(key, new Set());
        const set = controlledByAgreement.get(key)!;
        parties.forEach((p: any) => set.add(normalize(p.name)));
      }

      // Payee-based approach: Group royalties by payees (via writers)
      const payeeGroups = new Map<string, any[]>();
      const unmatched: any[] = [];

      // Build a quick lookup map: writer name -> payee
      const writerToPayeeMap = new Map<string, any>();
      if (payees && payees.length > 0) {
        for (const payee of payees) {
          if (payee.writer_id && payee.writers) {
            const writerName = normalize(payee.writers.writer_name);
            writerToPayeeMap.set(writerName, payee);
          }
        }
      }

      for (const royalty of allRoyalties) {
        const gross = royalty.gross_royalty_amount || 0;
        const names = royalty.work_writers ? splitWriters(royalty.work_writers) : [];
        
        if (names.length === 0 || gross <= 0) {
          unmatched.push(royalty);
          continue;
        }

        // Find matching payees for these writer names
        const matchingPayees = names
          .map((name: string) => writerToPayeeMap.get(normalize(name)))
          .filter(Boolean);

        if (matchingPayees.length === 0) {
          unmatched.push(royalty);
          continue;
        }

        // Split the royalty amount evenly among matching payees
        const perPayee = gross / matchingPayees.length;
        for (const payee of matchingPayees) {
          const payeeKey = `payee_${payee.id}`;
          if (!payeeGroups.has(payeeKey)) {
            payeeGroups.set(payeeKey, []);
          }
          payeeGroups.get(payeeKey)!.push({ 
            ...royalty, 
            payee_info: payee, 
            allocated_amount: perPayee 
          });
        }
      }

      // Check if we have any royalties to process
      if (payeeGroups.size === 0 && unmatched.length === 0) {
        toast({
          title: "Info",
          description: "No royalties found to process",
        });
        return false;
      }

      // Create payouts for each payee group
      const payoutResults: any[] = [];

      for (const [payeeKey, payeeRoyalties] of payeeGroups) {
        const payee = payeeRoyalties[0].payee_info;
        const totalAmount = payeeRoyalties.reduce((sum, r) => sum + (r.allocated_amount ?? r.gross_royalty_amount ?? 0), 0);

        if (totalAmount <= 0) continue;

        try {
          // Get or create contact for this payee's writer
          let contactId = null;
          if (payee.writer_id && payee.writers) {
            const { data: existingContact } = await supabase
              .from('contacts')
              .select('id')
              .eq('user_id', user.id)
              .eq('name', payee.writers.writer_name)
              .eq('contact_type', 'writer')
              .maybeSingle();

            if (existingContact) {
              contactId = existingContact.id;
            } else {
              const { data: newContact, error: contactError } = await supabase
                .from('contacts')
                .insert({
                  user_id: user.id,
                  name: payee.writers.writer_name,
                  contact_type: 'writer'
                })
                .select('id')
                .single();

              if (!contactError && newContact) {
                contactId = newContact.id;
              }
            }
          }

          // Skip if we couldn't get a contact_id
          if (!contactId) {
            console.error(`Could not find or create contact for payee ${payee.payee_name}`);
            continue;
          }

          // Create payout for this payee using single object (not array)
          const { data: payout, error: payoutError } = await supabase
            .from('payouts')
            .insert({
              user_id: user.id,
              client_id: contactId, // Required by NOT NULL constraint
              payee_id: payee.id, // Required by validation trigger
              period: `Q${selectedQuarter} ${selectedYear}`,
              period_start: `${selectedYear}-${(selectedQuarter - 1) * 3 + 1}-01`,
              period_end: `${selectedYear}-${selectedQuarter * 3}-${selectedQuarter === 4 ? 31 : 30}`,
              gross_royalties: totalAmount,
              total_expenses: 0,
              net_payable: totalAmount,
              amount_due: totalAmount,
              status: 'pending',
              notes: `Auto-generated for ${payee.payee_name} from batch ${batch?.batch_id || id} - Q${selectedQuarter} ${selectedYear}`,
            })
            .select()
            .single();

          if (payoutError) {
            console.error(`Error creating payout for ${payee.payee_name}:`, payoutError);
            continue;
          }

          // Link royalties to the payout
          const payoutRoyalties = payeeRoyalties.map(royalty => ({
            payout_id: payout.id,
            royalty_id: royalty.id,
            allocated_amount: royalty.allocated_amount ?? (royalty.gross_royalty_amount || 0),
          }));

          const { error: linkError } = await supabase
            .from('payout_royalties')
            .insert(payoutRoyalties);

          if (linkError) {
            console.error(`Error linking royalties for ${payee.payee_name}:`, linkError);
            continue;
          }

          payoutResults.push({
            payee_name: payee.payee_name,
            payee_id: payee.id,
            payout_id: payout.id,
            amount: totalAmount,
            royalty_count: payeeRoyalties.length,
          });
        } catch (error) {
          console.error(`Error processing payee ${payee.payee_name}:`, error);
          toast({
            title: "Warning",
            description: `Failed to create payout for ${payee.payee_name}`,
            variant: "destructive",
          });
        }
      }

      // Validate that all royalties have matching payees before processing
      if (unmatched.length > 0) {
        const unmatchedTotal = unmatched.reduce((sum, r) => sum + (r.gross_royalty_amount || 0), 0);
        
        if (unmatchedTotal > 0) {
          const unmatchedWriters = Array.from(new Set(
            unmatched
              .filter(r => r.work_writers)
              .flatMap(r => splitWriters(r.work_writers))
          ));
          
          toast({
            title: "Cannot Process Batch",
            description: `${unmatched.length} royalties (totaling $${unmatchedTotal.toFixed(2)}) cannot be matched to existing payees. Writers without payees: ${unmatchedWriters.slice(0, 5).join(', ')}${unmatchedWriters.length > 5 ? '...' : ''}. Please create payees for these writers before processing.`,
            variant: "destructive",
          });
          return false;
        }
      }

      // Update the batch to mark it as processed
      const { error: updateError } = await supabase
        .from('reconciliation_batches')
        .update({
          processed_at: new Date().toISOString(),
          processed_by_user_id: user.id,
          processing_count: (batch?.processing_count || 0) + 1,
        })
        .eq('id', id);

      if (updateError) throw updateError;

      toast({
        title: "Success",
        description: `Batch processed successfully. Created ${payoutResults.length} payee-based payouts.`,
      });

      await fetchBatches();
      return true;

    } catch (error: any) {
      console.error('Error processing batch:', error);
      toast({
        title: "Error",
        description: "Failed to process batch to writer payouts",
        variant: "destructive",
      });
      return false;
    }
  };

  const unprocessBatch = async (id: string) => {
    if (!user) return false;

    try {
      // Find all payouts that were created from this batch
      const batch = batches.find(b => b.id === id);
      const { data: payouts, error: payoutError } = await supabase
        .from('payouts')
        .select('id')
        .eq('user_id', user.id)
        .like('notes', `%from batch ${batch?.batch_id || id}%`);

      if (payoutError) throw payoutError;

      if (payouts && payouts.length > 0) {
        // Delete payout royalty links
        const { error: deleteLinksError } = await supabase
          .from('payout_royalties')
          .delete()
          .in('payout_id', payouts.map(p => p.id));

        if (deleteLinksError) throw deleteLinksError;

        // Delete the payouts
        const { error: deletePayoutsError } = await supabase
          .from('payouts')
          .delete()
          .in('id', payouts.map(p => p.id));

        if (deletePayoutsError) throw deletePayoutsError;
      }

      // Update the batch to mark it as unprocessed
      const { error: updateError } = await supabase
        .from('reconciliation_batches')
        .update({
          processed_at: null,
          processing_count: 0,
          unprocessed_at: new Date().toISOString(),
          unprocessed_by_user_id: user.id,
        })
        .eq('id', id);

      if (updateError) throw updateError;

      toast({
        title: "Success",
        description: "Batch unprocessed successfully. Associated payouts have been removed.",
      });

      await fetchBatches();
      return true;
    } catch (error: any) {
      console.error('Error unprocessing batch:', error);
      toast({
        title: "Error",
        description: "Failed to unprocess batch",
        variant: "destructive",
      });
      return false;
    }
  };

  useEffect(() => {
    fetchBatches();
  }, [user]);

  return {
    batches,
    loading,
    createBatch,
    updateBatch,
    deleteBatch,
    linkBatchToAllocations,
    unlinkStatement,
    processBatch,
    unprocessBatch,
    refreshBatches: fetchBatches,
  };
}
